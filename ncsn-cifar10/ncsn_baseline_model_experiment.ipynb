{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIdkss3o7_zN",
        "outputId": "e8fada63-85f1-4519-b1e5-46ee15541bc6"
      },
      "outputs": [],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU6N0RbM8Oum"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7L35fBF8hSK",
        "outputId": "903a6640-0389-4b00-bb26-c2baf6e87251"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Znttw8vY9s4I",
        "outputId": "d06c2b85-088f-424a-aa6d-3bf2f588b0d2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ==================== Model Architecture ====================\n",
        "class ConditionalInstanceNorm2dPlus(nn.Module):\n",
        "    def __init__(self, num_features, num_classes, bias=True):\n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.bias = bias\n",
        "        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False, track_running_stats=False)\n",
        "        if bias:\n",
        "            self.embed = nn.Embedding(num_classes, num_features * 3)\n",
        "            self.embed.weight.data[:, :2 * num_features].normal_(1, 0.02)\n",
        "            self.embed.weight.data[:, 2 * num_features:].zero_()\n",
        "        else:\n",
        "            self.embed = nn.Embedding(num_classes, 2 * num_features)\n",
        "            self.embed.weight.data.normal_(1, 0.02)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        h = self.instance_norm(x)\n",
        "        if self.bias:\n",
        "            gamma, alpha, beta = self.embed(y).chunk(3, dim=-1)\n",
        "            out = gamma.view(-1, self.num_features, 1, 1) * h + alpha.view(-1, self.num_features, 1, 1) * x + beta.view(-1, self.num_features, 1, 1)\n",
        "        else:\n",
        "            gamma, alpha = self.embed(y).chunk(2, dim=-1)\n",
        "            out = gamma.view(-1, self.num_features, 1, 1) * h + alpha.view(-1, self.num_features, 1, 1) * x\n",
        "        return out\n",
        "\n",
        "\n",
        "class ConditionalResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_classes, resample=None, activation=nn.ELU()):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.resample = resample\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.norm1 = ConditionalInstanceNorm2dPlus(in_channels, num_classes)\n",
        "        self.norm2 = ConditionalInstanceNorm2dPlus(out_channels, num_classes)\n",
        "\n",
        "        if resample == 'down':\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, stride=2)\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, 1, stride=2)\n",
        "        elif resample == 'up':\n",
        "            self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, 3, padding=1)\n",
        "            self.conv2 = nn.ConvTranspose2d(out_channels, out_channels, 3, padding=1, stride=2, output_padding=1)\n",
        "            self.shortcut = nn.ConvTranspose2d(in_channels, out_channels, 1, stride=2, output_padding=1)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        h = self.norm1(x, y)\n",
        "        h = self.activation(h)\n",
        "        h = self.conv1(h)\n",
        "        h = self.norm2(h, y)\n",
        "        h = self.activation(h)\n",
        "        h = self.conv2(h)\n",
        "\n",
        "        if self.shortcut is not None:\n",
        "            return h + self.shortcut(x)\n",
        "        else:\n",
        "            return h + x\n",
        "\n",
        "\n",
        "class RefineNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.refine1 = ConditionalResidualBlock(in_channels, out_channels, num_classes, resample=None)\n",
        "        self.refine2 = ConditionalResidualBlock(out_channels, out_channels, num_classes, resample=None)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        h = self.refine1(x, y)\n",
        "        h = self.refine2(h, y)\n",
        "        return h\n",
        "\n",
        "\n",
        "class NCSNModel(nn.Module):\n",
        "    def __init__(self, num_classes=10, ngf=128):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.ngf = ngf\n",
        "        self.activation = nn.ELU()\n",
        "\n",
        "        # Initial: RGB -> Features\n",
        "        self.begin_conv = nn.Conv2d(3, ngf, 3, padding=1)\n",
        "\n",
        "        # Downsampling\n",
        "        self.res1 = ConditionalResidualBlock(ngf, ngf, num_classes, resample='down')\n",
        "        self.res2 = ConditionalResidualBlock(ngf, 2*ngf, num_classes, resample='down')\n",
        "        self.res3 = ConditionalResidualBlock(2*ngf, 2*ngf, num_classes, resample='down')\n",
        "\n",
        "        # Middle\n",
        "        self.res4 = ConditionalResidualBlock(2*ngf, 2*ngf, num_classes, resample=None)\n",
        "\n",
        "        # Upsampling\n",
        "        self.refine1 = RefineNet(2*ngf, 2*ngf, num_classes)\n",
        "        self.res5 = ConditionalResidualBlock(2*ngf, 2*ngf, num_classes, resample='up')\n",
        "        self.refine2 = RefineNet(2*ngf, 2*ngf, num_classes)\n",
        "        self.res6 = ConditionalResidualBlock(2*ngf, ngf, num_classes, resample='up')\n",
        "        self.refine3 = RefineNet(ngf, ngf, num_classes)\n",
        "        self.res7 = ConditionalResidualBlock(ngf, ngf, num_classes, resample='up')\n",
        "        self.refine4 = RefineNet(ngf, ngf, num_classes)\n",
        "\n",
        "        # Final Features -> RGB\n",
        "        self.norm_final = ConditionalInstanceNorm2dPlus(ngf, num_classes)\n",
        "        self.end_conv = nn.Conv2d(ngf, 3, 3, padding=1)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        h = self.begin_conv(x)\n",
        "\n",
        "        h1 = self.res1(h, y)\n",
        "        h2 = self.res2(h1, y)\n",
        "        h3 = self.res3(h2, y)\n",
        "\n",
        "\n",
        "        h = self.res4(h3, y)\n",
        "\n",
        "\n",
        "        h = self.refine1(h, y)\n",
        "        h = self.res5(h, y)\n",
        "        h = h + h2\n",
        "        h = self.refine2(h, y)\n",
        "        h = self.res6(h, y)\n",
        "        h = h + h1\n",
        "        h = self.refine3(h, y)\n",
        "        h = self.res7(h, y)\n",
        "        h = self.refine4(h, y)\n",
        "\n",
        "\n",
        "        h = self.norm_final(h, y)\n",
        "        h = self.activation(h)\n",
        "        h = self.end_conv(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "\n",
        "# ==================== Loss Functions ====================\n",
        "def anneal_dsm_score_estimation(scorenet, samples, sigmas, anneal_power=2.0):\n",
        "    batch_size = samples.shape[0]\n",
        "\n",
        "    labels = torch.randint(0, len(sigmas), (batch_size,), device=samples.device)\n",
        "    used_sigmas = sigmas[labels].view(batch_size, *([1] * len(samples.shape[1:])))\n",
        "\n",
        "    noise = torch.randn_like(samples) * used_sigmas\n",
        "    perturbed_samples = samples + noise\n",
        "\n",
        "    predicted_score = scorenet(perturbed_samples, labels)\n",
        "    target = -noise / (used_sigmas ** 2)\n",
        "\n",
        "    losses = 0.5 * ((predicted_score - target) ** 2).sum(dim=(1, 2, 3))\n",
        "    loss_weights = (used_sigmas.squeeze() ** anneal_power)\n",
        "    weighted_loss = (losses * loss_weights).mean()\n",
        "\n",
        "\n",
        "\n",
        "    unweighted_loss = losses.mean()\n",
        "\n",
        "    channel_losses = 0.5 * ((predicted_score - target) ** 2).sum(dim=(2, 3))\n",
        "    loss_per_channel = {\n",
        "        'loss_channel_0': channel_losses[:, 0].mean().item(),\n",
        "        'loss_channel_1': channel_losses[:, 1].mean().item(),\n",
        "        'loss_channel_2': channel_losses[:, 2].mean().item(),\n",
        "    }\n",
        "\n",
        "    unique_labels = torch.unique(labels)\n",
        "    loss_per_sigma = {}\n",
        "    for lbl in unique_labels:\n",
        "        mask = labels == lbl\n",
        "        if mask.sum() > 0:\n",
        "            loss_per_sigma[f'loss_sigma_{lbl.item()}'] = losses[mask].mean().item()\n",
        "\n",
        "    l1_loss = torch.abs(predicted_score - target).sum(dim=(1, 2, 3)).mean()\n",
        "\n",
        "    grad_norm = torch.norm(predicted_score.view(batch_size, -1), dim=1).mean()\n",
        "    target_norm = torch.norm(target.view(batch_size, -1), dim=1).mean()\n",
        "\n",
        "    loss_dict = {\n",
        "        'loss_weighted': weighted_loss.item(),\n",
        "        'loss_unweighted': unweighted_loss.item(),\n",
        "        'loss_l1': l1_loss.item(),\n",
        "        'grad_norm': grad_norm.item(),\n",
        "        'target_norm': target_norm.item(),\n",
        "        'sigma_mean': used_sigmas.mean().item(),\n",
        "        'sigma_std': used_sigmas.std().item(),\n",
        "        **loss_per_channel,\n",
        "        **loss_per_sigma\n",
        "    }\n",
        "\n",
        "    return weighted_loss, loss_dict\n",
        "\n",
        "\n",
        "# ==================== Sampling ====================\n",
        "@torch.no_grad()\n",
        "def anneal_langevin_dynamics(scorenet, x_init, sigmas, n_steps_each=100, step_lr=0.00002,\n",
        "                             log_intermediate=False, log_interval=10):\n",
        "    x = x_init.clone()\n",
        "    intermediate_images = []\n",
        "\n",
        "    for idx, sigma in enumerate(sigmas):\n",
        "        sigma_val = sigma.item()\n",
        "        labels = torch.ones(x.shape[0], device=x.device, dtype=torch.long) * idx\n",
        "        step_size = step_lr * (sigma_val / sigmas[-1].item()) ** 2\n",
        "\n",
        "        for step in range(n_steps_each):\n",
        "            noise = torch.randn_like(x) * np.sqrt(step_size * 2)\n",
        "            grad = scorenet(x, labels)\n",
        "            x = x + step_size * grad + noise\n",
        "\n",
        "            if log_intermediate and (step % log_interval == 0 or step == n_steps_each - 1):\n",
        "                intermediate_images.append({\n",
        "                    'sigma_idx': idx,\n",
        "                    'step': step,\n",
        "                    'image': x.clone()\n",
        "                })\n",
        "\n",
        "    if log_intermediate:\n",
        "        return x, intermediate_images\n",
        "    return x\n",
        "\n",
        "\n",
        "# ==================== Configuration ====================\n",
        "class NCSNConfig:\n",
        "    num_classes = 10\n",
        "    ngf = 128\n",
        "\n",
        "    sigma_begin = 1.0\n",
        "    sigma_end = 0.01\n",
        "\n",
        "    batch_size = 128\n",
        "    num_epochs = 100\n",
        "    lr = 0.001\n",
        "    lr_decay_factor = 0.1\n",
        "    lr_decay_epochs = [70, 90]\n",
        "\n",
        "    n_steps_each = 100\n",
        "    step_lr = 0.00002\n",
        "\n",
        "    image_size = 32\n",
        "    num_workers = 4\n",
        "    prefetch_factor = 2\n",
        "\n",
        "    log_interval = 50\n",
        "    sample_interval = 500\n",
        "    num_samples = 64\n",
        "\n",
        "    checkpoint_dir = '/content/drive/MyDrive/cs236/assignments/final/checkpoints/'\n",
        "    save_every_n_epochs = 10\n",
        "    resume_from_checkpoint = None\n",
        "\n",
        "\n",
        "# ==================== Data Loading ====================\n",
        "def get_cifar10_dataloaders(batch_size, num_workers=4, prefetch_factor=2):\n",
        "    \"\"\"Load CIFAR-10 dataset with optimizations\"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=prefetch_factor,\n",
        "        persistent_workers=True if num_workers > 0 else False\n",
        "    )\n",
        "\n",
        "    return train_loader\n",
        "\n",
        "\n",
        "# ==================== Visualization ====================\n",
        "def denormalize(x):\n",
        "    \"\"\"Denormalize from [-1, 1] to [0, 1]\"\"\"\n",
        "    return (x + 1) / 2\n",
        "\n",
        "\n",
        "def save_sample_images(samples, filename, nrow=8):\n",
        "    \"\"\"Save generated samples as image grid\"\"\"\n",
        "    samples = denormalize(samples)\n",
        "    samples = torch.clamp(samples, 0, 1)\n",
        "    grid = torchvision.utils.make_grid(samples, nrow=nrow, padding=2)\n",
        "\n",
        "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, bbox_inches='tight', dpi=150)\n",
        "    plt.close()\n",
        "    return grid\n",
        "\n",
        "\n",
        "def create_intermediate_grid(intermediate_images, num_samples=8):\n",
        "    if not intermediate_images:\n",
        "        return None\n",
        "\n",
        "    selected_imgs = []\n",
        "    for img_data in intermediate_images[::max(1, len(intermediate_images)//10)]:\n",
        "        imgs = img_data['image'][:num_samples]\n",
        "        selected_imgs.append(denormalize(torch.clamp(imgs, -1, 1)))\n",
        "\n",
        "    if selected_imgs:\n",
        "        all_imgs = torch.cat(selected_imgs, dim=0)\n",
        "        grid = torchvision.utils.make_grid(all_imgs, nrow=num_samples, padding=2)\n",
        "        return grid\n",
        "    return None\n",
        "\n",
        "\n",
        "# ==================== Checkpoint Management ====================\n",
        "def save_checkpoint(model, optimizer, scheduler, epoch, loss, sigmas, filepath):\n",
        "    Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'loss': loss,\n",
        "        'sigmas': sigmas.cpu() if torch.is_tensor(sigmas) else sigmas,\n",
        "        'config': {\n",
        "            'num_classes': NCSNConfig.num_classes,\n",
        "            'ngf': NCSNConfig.ngf,\n",
        "            'sigma_begin': NCSNConfig.sigma_begin,\n",
        "            'sigma_end': NCSNConfig.sigma_end,\n",
        "        }\n",
        "    }\n",
        "    torch.save(checkpoint, filepath)\n",
        "    print(f\"Checkpoint saved: {filepath} (epoch {epoch})\")\n",
        "\n",
        "\n",
        "def load_checkpoint(filepath, model, optimizer=None, scheduler=None, device='cpu'):\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Checkpoint not found: {filepath}\")\n",
        "        return 0\n",
        "\n",
        "    checkpoint = torch.load(filepath, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    if scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch = checkpoint.get('epoch', 0)\n",
        "    print(f\"Checkpoint loaded from epoch {epoch}\")\n",
        "    return epoch + 1\n",
        "\n",
        "\n",
        "def find_latest_checkpoint(checkpoint_dir):\n",
        "    checkpoint_dir = Path(checkpoint_dir)\n",
        "\n",
        "    if not checkpoint_dir.exists():\n",
        "        print(f\"Checkpoint directory does not exist: {checkpoint_dir}\")\n",
        "        return None\n",
        "\n",
        "    latest_files = list(checkpoint_dir.glob('ncsn_latest_*.pth'))\n",
        "\n",
        "    if latest_files:\n",
        "        latest_checkpoint = None\n",
        "        latest_epoch = -1\n",
        "\n",
        "        for ckpt_path in latest_files:\n",
        "            try:\n",
        "                epoch_str = ckpt_path.stem.split('_')[-1]\n",
        "                epoch_num = int(epoch_str)\n",
        "\n",
        "                if epoch_num > latest_epoch:\n",
        "                    latest_epoch = epoch_num\n",
        "                    latest_checkpoint = ckpt_path\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "\n",
        "        if latest_checkpoint:\n",
        "            print(f\"Found latest checkpoint: {latest_checkpoint} (Epoch {latest_epoch})\")\n",
        "            return str(latest_checkpoint)\n",
        "\n",
        "    checkpoint_files = list(checkpoint_dir.glob('ncsn_epoch_*.pth'))\n",
        "\n",
        "    if not checkpoint_files:\n",
        "        print(\"No checkpoint files found in directory\")\n",
        "        return None\n",
        "\n",
        "    latest_checkpoint = None\n",
        "    latest_epoch = -1\n",
        "\n",
        "    for ckpt_path in checkpoint_files:\n",
        "        try:\n",
        "            epoch_str = ckpt_path.stem.split('_')[-1]\n",
        "            epoch_num = int(epoch_str)\n",
        "\n",
        "            if epoch_num > latest_epoch:\n",
        "                latest_epoch = epoch_num\n",
        "                latest_checkpoint = ckpt_path\n",
        "        except (ValueError, IndexError):\n",
        "            continue\n",
        "\n",
        "    if latest_checkpoint:\n",
        "        print(f\"Found latest checkpoint: {latest_checkpoint} (Epoch {latest_epoch})\")\n",
        "        return str(latest_checkpoint)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# ==================== Train ====================\n",
        "def train_ncsn():\n",
        "    wandb.init(\n",
        "        entity=\"tourists\",\n",
        "        project=\"ncsn-cifar10\",\n",
        "        name=\"baseline-ncsn\",\n",
        "        config={\n",
        "            \"model\": \"NCSN\",\n",
        "            \"dataset\": \"CIFAR-10\",\n",
        "            \"num_classes\": NCSNConfig.num_classes,\n",
        "            \"ngf\": NCSNConfig.ngf,\n",
        "            \"batch_size\": NCSNConfig.batch_size,\n",
        "            \"num_epochs\": NCSNConfig.num_epochs,\n",
        "            \"lr\": NCSNConfig.lr,\n",
        "            \"sigma_begin\": NCSNConfig.sigma_begin,\n",
        "            \"sigma_end\": NCSNConfig.sigma_end,\n",
        "            \"n_steps_each\": NCSNConfig.n_steps_each,\n",
        "            \"step_lr\": NCSNConfig.step_lr\n",
        "        }\n",
        "    )\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    sigmas = torch.tensor(\n",
        "        np.exp(np.linspace(\n",
        "            np.log(NCSNConfig.sigma_begin),\n",
        "            np.log(NCSNConfig.sigma_end),\n",
        "            NCSNConfig.num_classes\n",
        "        ))\n",
        "    ).float().to(device)\n",
        "    print(f\"Noise levels (sigmas): {sigmas}\")\n",
        "\n",
        "\n",
        "    model = NCSNModel(num_classes=NCSNConfig.num_classes, ngf=NCSNConfig.ngf).to(device)\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=NCSNConfig.lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer, milestones=NCSNConfig.lr_decay_epochs, gamma=NCSNConfig.lr_decay_factor\n",
        "    )\n",
        "\n",
        "    start_epoch = 0\n",
        "    if NCSNConfig.resume_from_checkpoint:\n",
        "        start_epoch = load_checkpoint(\n",
        "            NCSNConfig.resume_from_checkpoint, model, optimizer, scheduler, device\n",
        "        )\n",
        "    else:\n",
        "        latest_ckpt = find_latest_checkpoint(NCSNConfig.checkpoint_dir)\n",
        "        if latest_ckpt:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"RESUMING TRAINING from {latest_ckpt}\")\n",
        "            print(f\"{'='*60}\\n\")\n",
        "            start_epoch = load_checkpoint(latest_ckpt, model, optimizer, scheduler, device)\n",
        "        else:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"STARTING FRESH TRAINING (no checkpoints found)\")\n",
        "            print(f\"{'='*60}\\n\")\n",
        "\n",
        "    train_loader = get_cifar10_dataloaders(\n",
        "        NCSNConfig.batch_size,\n",
        "        NCSNConfig.num_workers,\n",
        "        NCSNConfig.prefetch_factor\n",
        "    )\n",
        "\n",
        "    # ==================== Training loop ====================\n",
        "    global_step = start_epoch * len(train_loader)\n",
        "\n",
        "    for epoch in range(start_epoch, NCSNConfig.num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_metrics = {}\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NCSNConfig.num_epochs}\")\n",
        "\n",
        "        for batch_idx, (images, _) in enumerate(pbar):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "\n",
        "            # FORWARD\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss, loss_dict = anneal_dsm_score_estimation(model, images, sigmas)\n",
        "\n",
        "            # BACKWARD\n",
        "            loss.backward()\n",
        "\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            loss_dict['grad_norm_clipped'] = grad_norm.item()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            global_step += 1\n",
        "\n",
        "            for key, val in loss_dict.items():\n",
        "                if key not in epoch_metrics:\n",
        "                    epoch_metrics[key] = []\n",
        "                epoch_metrics[key].append(val)\n",
        "\n",
        "            if global_step % NCSNConfig.log_interval == 0:\n",
        "                log_dict = {\n",
        "                    \"train/loss\": loss.item(),\n",
        "                    \"train/epoch\": epoch,\n",
        "                    \"train/lr\": optimizer.param_groups[0]['lr'],\n",
        "                    \"train/global_step\": global_step,\n",
        "                }\n",
        "                for key, val in loss_dict.items():\n",
        "                    log_dict[f\"train/{key}\"] = val\n",
        "\n",
        "                wandb.log(log_dict, step=global_step)\n",
        "\n",
        "            if global_step % NCSNConfig.sample_interval == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    x_init = torch.randn(NCSNConfig.num_samples, 3, 32, 32).to(device) * sigmas[0]\n",
        "\n",
        "                    # SAMPLING\n",
        "                    samples, intermediate_imgs = anneal_langevin_dynamics(\n",
        "                        model, x_init, sigmas,\n",
        "                        n_steps_each=NCSNConfig.n_steps_each,\n",
        "                        step_lr=NCSNConfig.step_lr,\n",
        "                        log_intermediate=True,\n",
        "                        log_interval=20\n",
        "                    )\n",
        "\n",
        "                    sample_path = f'{NCSNConfig.checkpoint_dir}samples/ncsn_samples_step_{global_step}.png'\n",
        "                    grid = save_sample_images(samples, sample_path)\n",
        "\n",
        "                    prog_grid = create_intermediate_grid(intermediate_imgs, num_samples=8)\n",
        "\n",
        "                    if prog_grid is not None:\n",
        "                        prog_path = f'{NCSNConfig.checkpoint_dir}samples/ncsn_progression_step_{global_step}.png'\n",
        "                        Path(prog_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "                        plt.figure(figsize=(16, 10))\n",
        "                        plt.imshow(prog_grid.permute(1, 2, 0).cpu().numpy())\n",
        "                        plt.axis('off')\n",
        "                        plt.title(f'Sampling Progression - Step {global_step}')\n",
        "                        plt.tight_layout()\n",
        "                        plt.savefig(prog_path, bbox_inches='tight', dpi=150)\n",
        "                        plt.close()\n",
        "\n",
        "                    wandb_logs = {\n",
        "                        \"samples/final\": wandb.Image(\n",
        "                            grid.permute(1, 2, 0).cpu().numpy(),\n",
        "                            caption=f\"Final samples - Step {global_step}\"\n",
        "                        )\n",
        "                    }\n",
        "\n",
        "                    if prog_grid is not None:\n",
        "                        wandb_logs[\"samples/progression\"] = wandb.Image(\n",
        "                            prog_grid.permute(1, 2, 0).cpu().numpy(),\n",
        "                            caption=f\"Sampling progression - Step {global_step}\"\n",
        "                        )\n",
        "\n",
        "                    sample_images = denormalize(torch.clamp(samples[:16], -1, 1))\n",
        "                    for idx in range(min(16, sample_images.shape[0])):\n",
        "                        wandb_logs[f\"samples/individual_{idx}\"] = wandb.Image(\n",
        "                            sample_images[idx].permute(1, 2, 0).cpu().numpy(),\n",
        "                            caption=f\"Sample {idx} - Step {global_step}\"\n",
        "                        )\n",
        "\n",
        "                    wandb.log(wandb_logs, step=global_step)\n",
        "                    print(f\"\\nGenerated and logged {NCSNConfig.num_samples} samples at step {global_step}\")\n",
        "\n",
        "                model.train()\n",
        "\n",
        "            pbar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"\\nEpoch {epoch+1} - Average Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "        epoch_avg_metrics = {\n",
        "            f\"epoch/{key}\": np.mean(vals)\n",
        "            for key, vals in epoch_metrics.items()\n",
        "        }\n",
        "        epoch_avg_metrics[\"epoch/avg_loss\"] = avg_epoch_loss\n",
        "        epoch_avg_metrics[\"epoch/number\"] = epoch + 1\n",
        "\n",
        "        wandb.log(epoch_avg_metrics, step=global_step)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % NCSNConfig.save_every_n_epochs == 0:\n",
        "            checkpoint_path = f'{NCSNConfig.checkpoint_dir}ncsn_epoch_{epoch+1:03d}.pth'\n",
        "            save_checkpoint(model, optimizer, scheduler, epoch, avg_epoch_loss, sigmas, checkpoint_path)\n",
        "\n",
        "        latest_path = f'{NCSNConfig.checkpoint_dir}ncsn_latest_{epoch+1:03d}.pth'\n",
        "\n",
        "        old_latest_files = list(Path(NCSNConfig.checkpoint_dir).glob('ncsn_latest_*.pth'))\n",
        "        for old_file in old_latest_files:\n",
        "            try:\n",
        "                old_file.unlink()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        save_checkpoint(model, optimizer, scheduler, epoch, avg_epoch_loss, sigmas, latest_path)\n",
        "\n",
        "    final_path = f'{NCSNConfig.checkpoint_dir}ncsn_final.pth'\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'sigmas': sigmas.cpu(),\n",
        "        'config': {\n",
        "            'num_classes': NCSNConfig.num_classes,\n",
        "            'ngf': NCSNConfig.ngf,\n",
        "        }\n",
        "    }, final_path)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training completed successfully!\")\n",
        "    print(f\"Final model saved to: {final_path}\")\n",
        "    print(f\"Total checkpoints saved: {NCSNConfig.num_epochs // NCSNConfig.save_every_n_epochs}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    wandb.finish()\n",
        "\n",
        "    return model, sigmas\n",
        "\n",
        "\n",
        "# ==================== Run Training ====================\n",
        "if __name__ == \"__main__\":\n",
        "    model, sigmas = train_ncsn()\n",
        "    print(\"Training completed!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mObQ76SdsUhW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
